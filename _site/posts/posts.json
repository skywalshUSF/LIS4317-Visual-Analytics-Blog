[
  {
    "path": "posts/2025-11-03-module-11-assignment/",
    "title": "Module 11: Edward R. Tufte",
    "description": "Tufte and C. Minard in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-11-03",
    "categories": [],
    "contents": "\r\nMy assignment for module # 11 is to review Dr. Piwek’s posting on Tufte and C. Minard in R and see if I can generate one of the visualizations he discussed in his post that include:\r\nMarginal histogram scatter plot\r\nDot-dash plot in ggplot2\r\nDot-dash plot in lattice\r\nOr any one I like the best.\r\nMy additional goal for this assignment is to take a practical visualization and try to represent it by the data or what the visualization is trying to capture.\r\nInstall the packages\r\nIn order to run the visualization of my choice, I installed the ‘ggthemes’ package.\r\nRun those packages in the background\r\nThe package successfully runs in the background, as well as the ‘ggplot2’ package that is already installed.\r\nThe Code\r\nAfter reading the information from http://motioninsocial.com/tufte/#introduction\r\nI chose to replicate the ‘Minimal line plot in ggplot2’ using the ‘ggplot2’ & ‘ggthemes’ packages in ‘R - the most powerful open-source statistical programming language’ - to replicate the excellent visualization practices developed by Edward Tufte.\r\n\r\n\r\n\r\nI chose to reproduce this particular visualization because Piwek (2017) suggests that “We start by plotting the most basic graph from page 65 of The Visual Display of Quantitative Information - a minimal line plot. This one is important because it illustrates the most elemental principle - that of minimalism with reduced ‘data-ink’”. Piwek (2017) then quotes Tufte (1983) explaining that “the ‘data-ink’ (total ink used to print the graphic) ratio should be equal to ‘1 - proportion of graphic that can be erased without loss of data-information’.” I found the removal of base R’s plots to be interesting and displays a useful feature of ‘ggplot’ to modify the theme layer.\r\nReferences:\r\nEdward Tufte, The Visual Display of Quantitative Information (Cheshire, 1983), p. 65\r\nPiwek, L. (2017). Tufte in R. Motioninsocial.com. Retrieved November 3, 2025, from http://motioninsocial.com/tufte/#introduction\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-11-03-module-11-assignment/Mod11Vis.png?raw=true",
    "last_modified": "2025-11-03T10:47:06-05:00",
    "input_file": "module-11-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-26-module-10-assignment/",
    "title": "Module 10: Time Series and Visualization",
    "description": "ggplot2 and time series",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-26",
    "categories": [],
    "contents": "\r\nReview the reading resources and post on your blog a new entry with your work with ggplot2 and time series (try yourself) and discuss the input of visualization on time series analysis.\r\n\r\n\r\n# Load ggplot2 library for the visualization's dataset and plot\r\nlibrary(ggplot2)\r\n\r\n# Load the economics dataset and store the results in a dataframe\r\ndata(\"economics\")\r\nmyDF <- economics\r\n\r\n# Explore the structure and statistics of the dataframe\r\nstr(myDF)\r\n\r\nspc_tbl_ [574 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\r\n $ date    : Date[1:574], format: \"1967-07-01\" ...\r\n $ pce     : num [1:574] 507 510 516 512 517 ...\r\n $ pop     : num [1:574] 198712 198911 199113 199311 199498 ...\r\n $ psavert : num [1:574] 12.6 12.6 11.9 12.9 12.8 11.8 11.7 12.3 11.7 12.3 ...\r\n $ uempmed : num [1:574] 4.5 4.7 4.6 4.9 4.7 4.8 5.1 4.5 4.1 4.6 ...\r\n $ unemploy: num [1:574] 2944 2945 2958 3143 3066 ...\r\n\r\nsummary(myDF)\r\n\r\n      date                 pce               pop        \r\n Min.   :1967-07-01   Min.   :  506.7   Min.   :198712  \r\n 1st Qu.:1979-06-08   1st Qu.: 1578.3   1st Qu.:224896  \r\n Median :1991-05-16   Median : 3936.8   Median :253060  \r\n Mean   :1991-05-17   Mean   : 4820.1   Mean   :257160  \r\n 3rd Qu.:2003-04-23   3rd Qu.: 7626.3   3rd Qu.:290291  \r\n Max.   :2015-04-01   Max.   :12193.8   Max.   :320402  \r\n    psavert          uempmed          unemploy    \r\n Min.   : 2.200   Min.   : 4.000   Min.   : 2685  \r\n 1st Qu.: 6.400   1st Qu.: 6.000   1st Qu.: 6284  \r\n Median : 8.400   Median : 7.500   Median : 7494  \r\n Mean   : 8.567   Mean   : 8.609   Mean   : 7771  \r\n 3rd Qu.:11.100   3rd Qu.: 9.100   3rd Qu.: 8686  \r\n Max.   :17.300   Max.   :25.200   Max.   :15352  \r\n\r\n# Create a simple bar chart that visualizes the average number of unemployed\r\n# in thousands by year from 1967 until 2012\r\nggplot(myDF, aes(x = date, y = unemploy)) +\r\n  geom_col()\r\n\r\n\r\n# This is the basic bar chart that ggplot2 generated. It contains x axis and y\r\n# axis labels, date for the 'date' variable, along with labels of numeric year\r\n# by decade, and unemploy for the 'unemploy' variable, along with a numeric scale\r\n# from 0-15000 to show the measurement of the y axis values.\r\n\r\n\r\nThe visualization above provides useful input for time series analysis. The bar graph style allowed me to instantly identify trend and cycles, levels, and changes. By plotting annual averages, the bar chart clearly shows a long term trend with an upward shift in total unemployment until late 2012, and economic cycles with multiple years. The height of the bars showed an absolute level of unemployment, emphasizing areas where the level changed drastically. While a line chart shows continuous changes on the x-axis time series better, a bar chart of annual averages properly measures how much the unemployment rate changed year after year.\r\nBefore considering adding a trend line using time series forecasting, I wanted to use a simple visualization style to confirm assumptions about the data. One of these assumptions was stationarity, which I learned from one of the supplementary materials of this module. In the case of my visualization, the unemployment time series is not stationary because the trend can shift upward or downward over the decades. Observing the patterns of peaks and troughs helped me out with improving the layers of the bar chart to more accurately represent the time series changes in unemployment over time.\r\n\r\n\r\n# Add color and a time series line to help observe the patterns of the time series\r\n# data. Also, improve the title of the chart and x and y labels.\r\nggplot(myDF, aes(x = date, y = unemploy)) +\r\n  geom_col(fill=\"#baeeba\",color=\"transparent\") + \r\n  geom_line(color=\"darkred\") + \r\n  stat_smooth() + \r\n# Set the labels and a strong, accurate title\r\nlabs(\r\n  title = \"Average Unemployment from 1967-2012\",\r\n  subtitle = \"Bar chart with time series regression line\",\r\n  x = \"Year\",\r\n  y = \"Average Unemployed - in Thousands\"\r\n)\r\n\r\n\r\n\r\nIt is easier to communicate findings and interpret the data with this visualization. The graph has a clear graph title and subtitle narrative, there are fill colors on the bars that are visually appealing, and some trend lines.\r\nUsing the geom_col() layer, I was able to add a green fill color to the bars of the graph that pertains to the narrative. There are two different trend line layers that have been used: geom_line() and stat_smooth(). The purpose of geom_line() with the red line is to take all y values and make a y value for every x value and connect the points. The red line at the top of the column bars connects into a line, helping with interpretation. The purpose of stat_smooth() with the blue line is to show a smooth, time series regression line. It takes the averages of the y values, and plots them into a smooth trend line, assisting in forecasting, hypothesis testing, and simulation.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-10-26-module-10-assignment/time_series.png?raw=true",
    "last_modified": "2025-10-26T13:10:12-04:00",
    "input_file": "module-10-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-22-module-9-assignment/",
    "title": "Module 9: Visualizing Multivariate Data",
    "description": "With ggplot2 and Corrgram",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-22",
    "categories": [],
    "contents": "\r\nCreate a multivariate graph\r\nHere is a png file of the correlation heatmap I created using ggplot2:\r\n\r\nInclude a short write-up\r\nInclude a short write-up (1-2 paragraphs) that addresses:\r\nWhich dataset you used an why\r\nI chose the ‘diamonds’ dataset from the ggplot2 library because it is structured with many diamond measurements and a lot of variables, which is great for a correlation matrix that is going to compare tons of values with one another.\r\nWhat relationships or insights your visualization reveals.\r\nI was able to visualize very interesting relationships between the variables. I noticed mostly positive correlations between the variables, some relationships that were not as significant, and a couple negative correlations. The correlation between diamond ‘depth’ and ‘table’ size appears to be negative, which tells me that as the total depth percentage of a diamond decreases, the width of the top of the diamond relative to the widest point also decreases. Also, I gained insight that the relationship between ‘x’, the length of the diamond in millimeters, and ‘table’ has a very low level of significance, which tells me that some values in the correlation may not be negative, but can have a very low occurrence by random chance.\r\nWhether multivariate visualization was effective for this data.\r\nIt turns out multivariate visualization was effective for the ‘diamonds’ data because it helped to understand correlations that require more advanced statistics to be able to compute, and it helped to understand more complicated relationships, such as the relationship between ‘depth’ and diamond ‘price’, and the relationship between ‘y’, the width of the diamond in millimeters, and ‘z’, the depth in millimeters.\r\nI have applied at least 3 of the design principles discussed in the module:\r\nThe first principle I used is Alignment. This allowed me to browse the variables that have been placed in a random or scattered orientation, and arrange them into a more ordered design, as well as aligning elements that are not in close adjacency with each other. My visualization was able to make the cells with a value of 1 go diagonal in order to get a more flexible glance at the distribution proportions, and I specified the correlation limits and midpoint in the ggplot() function while creating the Pearson Correlation legend.\r\nThe second principle I used is Repetition. This allowed me to bring independent elements that actually do share something in common together, and being able to associate the data properly. I used repetition when building a theme() function inside my geom_text() function as part of the ggplot2 heat map creation. After specifying the aes(), geom_tile(), and scale_fill_gradient() functions, I included the theme() function to repeat axis name arguments that each served different purposes: One was for the x text, another for x axis title, and a final one for the y axis title.\r\nThe third principle I used was Contrast. Contrast allowed me to emphasize the most important elements within my correlation heatmap so that the reader will know where they should look first or direct their eyes to the most important element. I utilized layer aesthetics when creating the ggplot heat map inside the ggplot() function. I started with the aes() functioon to include a fill equal to correlation that will allow the ‘diamonds’ cells to have color, then took advantage of setting the initial color of the tiles to white with the geom_tile() function to represent no value. Finally, to truly add color contrast to the correlation, I used the scale_fill_gradient() function to specify a color scheme that will show differences and relationships by color for each cell value that is from -1.0 to 1.0. Blue means low (negative), red means high (positive), and white now represents a neutral value (0) or midrange.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-10-22-module-9-assignment/mod9vis.png?raw=true",
    "last_modified": "2025-10-22T11:03:02-04:00",
    "input_file": "module-9-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-11-module-8-assignment/",
    "title": "Module 8: Correlation Analysis & ggplot2",
    "description": "Correlation and regression analysis using ggplot2",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-13",
    "categories": [],
    "contents": "\r\nChoose Your Dataset\r\nI used mtcars as the dataset\r\nImport the Data into RStudio\r\nI successfully imported the dataset into RStudio\r\nConduct Correlation or Regression Analysis\r\nCreate Your Visual in ggplot2\r\nHere is an image of my distribution visualization:\r\n\r\nReflect and share\r\nI began by exploring the variable relationships using the cor() function to compute correlation matrices and the lm() function for linear regression models.\r\nI then used ggplot2 and the gridExtra package to create a visual representation of multiple scatterplots to assess associations between the miles per gallon (mpg) variable and four other variables: Weight (wt), Horsepower (hp), Gear (gear), and Qsec (qsec), and added a regression line to show the predictive relationship between the variables.\r\nI applied design suggestions from Few and Yau, including a grid layout for side-by-side comparison, labeling axes clearly, minimizing clutter, and using a neutral color scheme.\r\nThe analysis revealed several interesting patterns and relationships between the variables. First, there was a negative correlation between MPG and Weight, suggesting that heavier cars get lower MPG. Also, a negative correlation between MPG and Horsepower, suggesting that cars with more Horsepower get fewer MPG. Looking at the correlation between miles per gallon and gears, there is a slight positive correlation with substantial variance, suggesting that vehicles with more gears get better MPG. Finally, the positive correlation between MPG and Qsec suggests that slower vehicles with a higher quarter-mile time also may get better MPG; however, there is a lot of variance in the scatter plot chart around the regression line.\r\nThere are multiple concepts from Few and Yau that helped me with my design choices. Few (2009) highlights two best practices that I used in my scatter plots: “Removing fill color to reduce over-plotting” (p. 266) and “Using grid lines to enhance comparisons between scatterplots.” (p. 266) If I used fill colors, there would be multiple regression lines interfering with other lines and cluttering points from a separate regression, and if I did not use grid lines, it would have been more challenging to estimate values. Few (2009) also suggests that “Comparing multiple scatterplots calls for a technique to make the comparison easier and more accurate.” (p. 278) This led me to use grid lines to improve comparisons between scatterplots and display multiple scatterplots that each deal with comparing an mtcars input variable to the MPG output (dependent) variable. Finally, Yau (2011) talks about a “scatterplot matrix,” which is “usually a square grid with all variables on both the vertical and horizontal.” (p. 189) The concept of comparing variables using an x-axis and a y-axis is what gave me the idea to arrange plots, and having multiple independent variables in the dataset gave me the idea to use gridExtra to arrange multiple plots.\r\nI used a gridExtra grid layout with two columns to place the four scatterplots in an organized manner. This helped place the scatterplots with negative correlation on top of the image and those with positive correlation at the bottom, making the visualization easier to understand. Yau (2011) suggests that “If two metrics are positively correlated, dots move higher up;” however, “if a negative correlation exists, the dots appear lower…” (p. 181) According to the data, Weight (wt) and Horsepower (hp) have a negative correlation to MPG due to a negative slope and most of the dots are below the regression line, while Gear (gear) and Qsec (qsec) have a positive correlation due to a positive slope and most of the dots are above the regression line.\r\nReferences:\r\nFew, S. (2009). Now you see it: simple visualization techniques for quantitative analysis. Analytics Press.\r\nYau, N. C. (2011). Visualize this: the flowing data guide to design, visualization, and statistics (1st edition). Wiley Publishing Inc.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-10-11-module-8-assignment/corr2.jpg?raw=true",
    "last_modified": "2025-10-13T12:00:28-04:00",
    "input_file": "module-8-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-04-module-7-assignment/",
    "title": "Module 7: Visual Distribution Analysis in R",
    "description": "Creating visualizations in R that are based on distribution analysis",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-04",
    "categories": [],
    "contents": "\r\nChoose a Dataset\r\nI chose Iris as my dataset\r\nImport the dataset into RStudio\r\nI successfully imported my dataset into RStudio\r\nCreate a Distribution Visualization\r\nHere is an image of my distribution visualization:\r\n\r\nWrite a Blog Post\r\nThe name of the dataset I chose to use is Iris.\r\nI used ggplot2 and the tidyverse to create a visual representation of the distribution of the iris dataset variables by species. The histogram visualization shows faceted distribution patterns for three iris species and their four variables (Petal.Length, Petal.Width, Sepal.Length, Sepal.Width) and adds a normal density curve along with a vertical line for the mean of each. Setosa consistently has the smallest Petal Length, Petal Width, and Sepal Length (according to the dashed lines representing the mean), with its distributions largely separate from the other two species and concentrated at lower values. Virginica generally has the largest Petal Width, Petal Length, and Sepal Length, and versicolor values for these first three graphs fall in between setosa and virginica. The pattern revealed by the visualization of the distributions is that the averages for the setosa are the least, with versicolor in the middle and then virginica with the most. Virginica does have the highest averages consecutively, except in the Sepal Width graph, where the versicolor average has the lowest values and the setosa average has the highest values. The data’s distributions appear to follow a symmetrical pattern, with some outliers skewing the curve and the mean slightly to the right and the left.\r\nMy design choice of faceted overlapping histograms aligned with both Few and Yau’s recommendations. It aligned with Yau’s recommendations by following a faceted analytical display (small multiples) for showing a clear distribution design; “it encourages readers to make comparisons across groups and categories” (Yau, 2011, p. 221), and adding a density curve,“You need to use the density() function to estimate the points for the curve” (Yau, 2011, p. 209). According to Few (2009), “Displays that combine multiple views of a common data set on a single screen are called by different names. When they’re used to make sense of the data,…I call them faceted analysis displays” (p. 107) and “histograms do a good job of displaying the overall shape of a distribution” (Few, 2009, p. 225). I used histograms to measure a continuous value variable and bars/lines to display the distributions. My visualization was able to clearly follow Few’s recommendations for clear distribution design, as my visualization was able to include spread, center, and shape. In addition, I included scaled x and y axes, added meaningful color “RGB” to separate the Species, and displayed the data on a white grid on the background of the histogram.\r\nI do agree with Few’s critique on how distributions are commonly presented in visual analytics, especially when he mentions that the three most important characteristics to summarize distribution values visually are spread, center, and shape (Few, 2009, p. 216). I also found the different shapes of the distributions interesting in visual analytics.\r\nReferences:\r\nFew, S. (2009). Now you see it: simple visualization techniques for quantitative analysis. Analytics Press.\r\nYau, N. C. (2011). Visualize this: the flowing data guide to design, visualization, and statistics (1st edition). Wiley Publishing Inc.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-10-04-module-7-assignment/LIS4317_mod7.png?raw=true",
    "last_modified": "2025-10-04T15:34:43-04:00",
    "input_file": "module-7-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-03-module-6-assignment/",
    "title": "Module 6: Visual Differences & Deviation Analysis via R",
    "description": "Create a basic data visualization using R, and critically reflect.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-03",
    "categories": [],
    "contents": "\r\nFollow the video and PowerPoint tutorial to create a basic chart in R using RStudio.\r\nI followed the video and PowerPoint tutorial on creating a basic chart in R using RStudio.\r\nUse either your own data or one of the sample datasets included in base R (e.g., mtcars, iris, airquality).\r\nI chose Iris as my dataset\r\nDesign a chart that highlights either: A comparison across variables (spotting differences), or A divergence from a norm, mean, or baseline (deviation analysis).\r\nI chose to do a comparison across variables spotting differences. The chart also explores divergence from a norm, mean, or baseline deviation analysis.\r\nExport or screenshot your plot, then post it on your blog.\r\nHere is the PNG image file for my plot:\r\n\r\nIn your blog post, reflect on the following:\r\nWhat kind of chart did you create?\r\nDid your visualization reveal any differences between groups or variables?\r\nDid it reveal any deviations from an expected value or benchmark?\r\nHow well does your chart align (or not align) with the principles discussed by Few (Chapter 9) and Yau (Chapter 7)?\r\nWhat challenges did you face in interpreting the visual output?\r\nI created a box-and-whisker plot that deals with a categorical variable called “Measurement” on the x-axis, and a quantitative variable called “Measurement Value” on the y-axis. This type of chart can summarize the distribution of the quantitative data, which in my case is Measurements, for each category. They show the median, quartiles, and the range of the data. I used the Iris dataset in this visualization to identify the variance in size of the length and width of petals and sepals, and to compare the medians of different flower species: setosa, versicolor, and virginica. As I explored the dataset, I was able to compare measurement values across other variables. My box-and-whisker plot revealed that the setosa has smaller measurements than the versicolor and virginica, except for the sepal width, where the setosa values are greater than both of the other two species. The plot also revealed that there is a lot more variance in petal length than in sepal width. The petal length ranges from 1-7 variation units, whereas the sepal width only ranges from 2-4.5 variation units. Likewise, there is a lot more variance in sepal length than there is in petal width.\r\nThe chart that I chose aligned very well with the principles discussed in the books. According to Yau (2011), “A quartile is one of three points in a dataset, which marks quarter spots. The middle quartile is the median or the halfway point;…” (p. 268). For discussion on the box plot, Few (2009) states that, “The lines that encode the top and bottom ranges of values are called whiskers, and the rectangle in the middle, which encodes the midspread, is called the box.” (p. 232). This knowledge from the readings implies that I know how to start at the center of a box plot and see how far the spread (variance) of values that have a particular size (2, 4, or 6) deviate from the median to the top or from the median to the bottom. While the box-and-whisker plot did seem to make it easy for me to identify outliers and compare a set of species for a single measurement, it also posed some major challenges. One of these challenges was the scatter plot points of one flower species overlapping the boxplots and other flower species points. Many points, mainly the ones within the boxes and the whiskers of the distribution, overlapped, making it difficult to accurately judge the true distribution. Also, it is challenging to distinguish if a dark patch in the plotting is due to a large number of overlapping points or simply a few very dark, high sized points. Despite the challenges I faced, I was able to make this visualization useful for comparing the distributions of four different Iris measurements with three different species all at the same time.\r\nReferences:\r\nFew, S. (2009). Now you see it: simple visualization techniques for quantitative analysis. Analytics Press.\r\nYau, N. C. (2011). Visualize this: the flowing data guide to design, visualization, and statistics (1st edition). Wiley Publishing Inc.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-10-03-module-6-assignment/SW_LIS4317mod6.png?raw=true",
    "last_modified": "2025-10-03T14:49:30-04:00",
    "input_file": "module-6-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-24-module-5-assignment/",
    "title": "Module 5: Create Your Own Visualizations assignment Plotly vs. Datawrapper",
    "description": "My interactive visualization that captures the design elements I learned.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-24",
    "categories": [],
    "contents": "\r\nOpen the dataset and explore the two columns: Average Position and Time.\r\nI used the Module # 5.xlsx file provided in the instructions and opened it in Microsoft Excel to view the data, including the average position and time columns.\r\nUse Plot.ly to:\r\nCreate at least one Ranking Chart (e.g., ordered bar chart, slope chart).\r\nI have successfully published my finished visualization on Plot.ly\r\nHere is a direct link to my Tableau visualization.\r\nhttps://chart-studio.plotly.com/~skylarwalsh/1/\r\nHere is an image:\r\n\r\nAt least one Part-to-Whole Chart (e.g., pie chart, stacked bar chart, donut chart).\r\nI have successfully published my finished visualization on Plot.ly\r\nHere is a direct link to my Tableau visualization.\r\nhttps://chart-studio.plotly.com/~skylarwalsh/3/\r\nHere is an image:\r\n\r\nThink about how these two design frameworks (Ranking and Part-to-Whole) reveal insights in your data.\r\nThe first visualization is a stacked bar chart that uses a ranking design framework to show how average position changes across 20 observations. Each bar is split into two different legend colors: orange, which is time, and blue, which represents average position. By stacking them, the chart makes it easy to compare the role of time progression against the variation in average position. The Ranking design of the bar chart is showing a sequential order. Each bar builds on the previous one, reinforcing the idea or concept of progression and cumulative growth.\r\nThe second visualization is a pie chart that uses a part-to-whole design framework to reveal insight about the data through Average Position by Time. The entire circle represents the complete dataset, which includes all observations and their average positions. Each slice represents the influence of a Time label, an Average Position value, and a Time percentage. By looking at the size of each slice, I can easily see which values had a larger or smaller share of the overall average positions.\r\nBlog Post Instructions:\r\nPost your visualizations on your blog.\r\nWrite a short description that includes:\r\nWhy you chose this dataset\r\nThe story or insights your visualizations tell.\r\nA quick reflection: What are the strengths and limitations of Part-to-Whole as a design framework?\r\nI selected the Module # 5.xlsx dataset for the Ranking visualization because it was easily accessible on the Canvas assignment page. For the Ranking design framework, a stacked bar chart is used because it allows the viewer to compare values across ordered observations while also clearly showing the progression along the ranked sequence of twenty observations. For the story and insight that it tells, the visualization shows that both time and average position increase steadily over 20 observations, with the blue piece (Average Position) stacked on top of the orange piece (Time). This makes it clear that average position improves consistently as time moves forward. The strengths of Ranking as a design framework are that it makes sequential order and progression easy to interpret and analyze, and it is effective for showing growth patterns. The limitations of Ranking as a design framework are that exact values may be harder to read compared to line charts and scatterplots, and proportions can be misinterpreted if two colors stacked on one bar share the same size in common.\r\nI selected the Module # 5.xlsx dataset for the Part-to-Whole visualization because it was easily accessible on the Canvas assignment page. For the part-to-whole design framework, a pie chart is used because it effectively shows how each time interval contributes to the overall average position dataset. For the story and insight that it tells, the visualization shows that some time intervals account for a larger portion of the overall average position, while others are influenced by only a small fraction. This provides insight into the distribution of average positions across time, showing which periods were most influential in having a certain effect on the total outcome. The strengths of Part-to-Whole as a design framework are that it clearly communicates proportions and it is easy to see both the balance and imbalance in the data. The limitations of Part-to-Whole as a design framework are that it is difficult to see the smallest slices on the chart and it is not as effective for showing trends or changes over time as I thought it would.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-09-24-module-5-assignment/images/20%20Observations%20of%20Average%20Position%20Over%20Time.png?raw=true",
    "last_modified": "2025-09-24T12:25:54-04:00",
    "input_file": "module-5-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-19-module-4-assignment/",
    "title": "Module 4: Time Series Visualization with Tableau Public",
    "description": "My time series visualization using Tableau Public.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-19",
    "categories": [],
    "contents": "\r\nDownload the Dataset\r\nI used the Monthly Modal Time Series dataset that contained 12 variables\r\nPrepare Your Data\r\nAfter opening the dataset and reviewing the provided variables, I selected at least six variables: Year, Month, Vehicle Revenue Miles, Vehicle Revenue Hours, Total Security Events, and Total Injuries.\r\nCreate Your Visualization\r\nI uploaded my clean dataset to Tableau Public and designed a time series visualization.\r\nShare You Work\r\nI have successfully published my finished visualization on Tableau Public.\r\nHere is a direct link to my Tableau visualization.\r\nhttps://public.tableau.com/views/Time_Series_Visualization/Sheet1?:language=en-US&publish=yes&:sid=&:redirect=auth&:display_count=n&:origin=viz_share_link\r\nHere is an image:\r\n\r\nThe six variables I selected are: Year, Month, Vehicle Revenue Miles, Vehicle Revenue Hours, Total Security Events, and Total Injuries. I chose the year and month variables because I can use them as time series data points to analyze trends. I chose vehicle revenue hours and vehicle revenue miles variables to measure the total time vehicles are in service and the total distance traveled by all vehicles when they are in service. Finally, I chose total security events and total injuries variables to track patterns in security-related incidents over time and analyze the total number of injuries over time.\r\nThe time series visualization I created shows an inverse relationship between the total number of security events and the total number of injuries over time. Specifically, as the total security events with an orange color legend show an increasing trend, the total injuries in a blue color legend display a decreasing trend. This suggests that a higher frequency of security events is associated with a decline in injuries. However, it is worth noting that there is a possible inaccuracy in the exact lines, mainly for the year 2025, which has an incomplete data point. Therefore, while there is a strong connection between security measures and injury prevention, the final year should be viewed with caution, as it is still a misleading figure in the data. The actual lines show that as the total number of injuries increases, so does the total number of security events. The exact lines are completely accurate because it is always important to take proper security measures in the case of an injury or to prevent injury.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-09-19-module-4-assignment/Mod4.png?raw=true",
    "last_modified": "2025-09-24T12:22:50-04:00",
    "input_file": "module-4-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-08-module-3-assignment/",
    "title": "Module 3: Refined Map with Color",
    "description": "My Geographic Map with the use of Adobe Illustrator and color principles.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-08",
    "categories": [],
    "contents": "\r\nSet Up Your Illustrator Canvas\r\nI opened Adobe Illustrator and created a new file, and set an appropriate ratio.\r\nImport Your Data Graphic\r\nI opened my Module 2 map file in Illustrator, and then positioned and scaled it to fit the artboard.\r\nConvert to Vector & Apply Color\r\nI was able to vectorize the map image I placed, ungrouped the traced elements, used the Swatches panel to apply a thoughtful color palette, and then edited my vector elements.\r\nEnhance with Labels & Legends\r\nI used the Type tool to add clear labels, created a legend that explains my color scale and symbols, and applied Gestalt principles.\r\nExport & Publish\r\nI saved my file, exported it as a high-resolution PNG, and I have the right title name for this blog post.\r\nHere is the map that I made changes to on Adobe Illustrator:\r\n\r\nReflect on Your Design\r\nMy map uses a sequential color scheme with a color scale that goes from light to dark, which is very effective for showing data that has a natural order for the afterschool meal program counts. The lighter shades (yellow, light green) indicate counties with fewer afterschool meal program sites, while the darker shades (green, dark green) indicate counties with more afterschool meal sites. I realized from the previous map that some cultures may not view the map scale the same way I would. Others might think orange means good and blue means bad. What makes the warmest color (yellow) on this map better than the other one (orange) is that it indicates rather than a county with a warmer color being bad, the warmer color just means that the county needs improvement. Additionally, my new map’s background has more light compared to the last one that was dark. I can see the blue color of the ocean and the gulf better, and the white color is very appropriate for showing the land, whereas the black/dark grey is contrasting the view of the land.\r\nThere were many vector elements that I added to this map. I have a compass symbol that represents my map’s position and orientation very well. I have a legend that I added below the compass to explain the color gradient used on the map. I have a large title to the left of the map that clearly states the map’s purpose, and it has a font style that is approachable and readable. The sushi icon is very nice on this map because the theme of this map is connected to meal programs. Finally, I added the names of the Florida counties each with their own number of program sites because I knew that most geographic maps would need text labels.\r\nGestalt principles really helped me guide my layout and grouping. Gestalt’s principle of Proximity really connects to this map, as the map’s layout uses proximity to group elements that are in common with each other. The title, compass, and legend are all placed near the main map of Florida, which means they are all a part of the same visual. Another principle that connects to this map is Figure/Ground. The map uses this principle to distinguish the important data from the background. The state of Florida is the figure, and it is layered against a white ground.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-09-08-module-3-assignment/mod3.png?raw=true",
    "last_modified": "2025-09-19T11:59:56-04:00",
    "input_file": "module-3-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-01-module-2-assignment/",
    "title": "Module 2 Assignment",
    "description": "My Geographic Map of Florida Afterschool Meal Program Sites by County",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-01",
    "categories": [],
    "contents": "\r\nFind a dataset with Addresses.\r\nFor this week’s assignment, I went to Google Dataset Search to find a dataset that I can create a geographic map visualization from using the Tableau Public Desktop Application. I entered these keywords into the search bar: “Florida food access location addresses.” The keywords interested me because access to food is a significant issue in the state of Florida. I found the following dataset to be very complete and accurate, and it included a column with full addresses:\r\nhttps://hub.arcgis.com/datasets/c0c7a78df6a7468f81ff705e5bbcf8dc_0/explore?location=27.763960%2C-83.741355%2C7.12\r\nI plan to use this data to create a visualization that shows which counties in Florida are doing a good job of providing access to food and which counties need improvement.\r\nSave to Google Drive\r\nNext, I had to download the .csv file, save it to my Google Drive, and then open it in Google Sheets.\r\nhttps://docs.google.com/spreadsheets/d/1VibZa5VExkB_CepFfdOKi2qTl939d6ARQ9gqqLZNLmc/edit?usp=sharing\r\n3 & 4. Install Tableau Public, Connect Data in Tableau\r\nI downloaded and installed Tableau Public, and linked it to my Google Drive.\r\n5 & 6. Build the Geographic Map, Export Map Image as .png file\r\nI used the dataset columns that Tableau recognized as geographic data types, such as county and zipcode to create a geovisualization that outlines the counties border lines and I was able to map a count variable to each county and label them accordingly. This allowed me to visualize which counties in Florida are doing a good job of providing access to food and which counties need improvement.\r\nHere is the map:\r\n\r\nPublish to the Blog\r\nI was able to create a new blog post with the image, and provide a link to my data source in Google Sheets.\r\nThere were some challenges that I faced. The first challenge was finding a dataset that had the right number of rows and columns. I needed a dataset that would not be too short on data nor have too much data. I solved this challenge by evaluating the record count when I enter the dataset and try to get enough results from the keywords that I typed. Another challenge that I faced was being able to choose which table names I wanted as my color and detail marks. Some table names convey visualized meaning out of the map while others might make the map appear strange. The solution to this was thinking about which variables I wanted to be illustrated, such as the afterschool count and the county site count.\r\nReflect on Visual Grammar\r\nThere are many additional graphic elements or Gestalt principles that I applied to improve clarity and insight:\r\nPoint size and color scales are helpful because they can help me to visually represent data attributes. In my map, I used warm colors such as brown and orange to indicate a bad value for a county and represent less Florida afterschool meal program sites, whereas the cool colors such as light blue and dark blue are used to indicate a good value for a county and represents a lot of Florida afterschool meal program sites. Rather than using little points to mark certain locations, I used a filled map that would replace little points with larger filled-in color coded counties and their boundaries to make it easier to outline the space that has more or less of Florida afterschool meal program sites.\r\nAdding text labels and tool tips are very helpful because they can help reveal details on every space of data and provide contextual information. Whether it is explaining what symbols mean or providing more specific data, these features can help improve any map that is created. I gave my counties labels so that the audience would know where the data for each county would be located and a numeric value for the number of programs. The labels are easy to read with a font color of white because the background color of my map is “dark.”\r\nProximity and similarity group patterns are helpful Gestalt principles for creating effective maps by arranging information into groups that are easy to understand and interpret. It can help reduce clutter, make the message of the map more clear, and make for more interesting results. The patterns show the counties that are doing a good job being close to larger cities and the pattern of counties that need more improvement appear to be in less populated rural areas.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-09-01-module-2-assignment/Sheet1resized.png?raw=true",
    "last_modified": "2025-09-01T17:46:11-04:00",
    "input_file": "module-2-assignment.knit.md"
  },
  {
    "path": "posts/2025-08-25-module-1-assignment-1/",
    "title": "Module 1 Assignment 1",
    "description": "Blog Setup & Data Visualization Analysis",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-08-25",
    "categories": [],
    "contents": "\r\nSet Up Your Course Blog\r\nWelcome to my first blog. In this post, I started by setting up my LIS4317 course blog.\r\nhttps://lis4317-visual-analytics-blog.netlify.app/\r\nFirst Blog Post: Select & Analyze a Visualization\r\nHere is a visualization of a global population addressing global drought risks using index score legends to indicate the level of risk.\r\n\r\nFleck, A. (2025). Mapping Global Drought Risk [Image]. Statista. https://www.statista.com/chart/25101/countries-by-drought-risk/\r\nAccording to the data visualization, I believe that it was created by a human designer and not generated by AI. My reasoning behind this is that in the website source, there is an author name, along with a publishing date, author email, website name, and a source name in the image, which are attributes that belong to a human designer. I also recognize that the decimal scales for each level of the drought risk are specific and that there could still be some bias found. The only ways this visualization could be created by AI was if the human designer tried to use some guided information from the AI to structure the image properly or if they had an AI reference link.\r\nReadings\r\nI have successfully visited the required chapters to read that were listed in this assignment.\r\nSyllabus Review\r\nAfter thoroughly reviewing the syllabus, I confirm that I understand all crucial information specified on it, especially the course structure, grading, and peer- review process. When I read the course description, I started to look forward to use certain platforms that we’ll focus on in this class, such as Tableu, Plotly, Google Sheets, open-source R, and Python. I also got to have a really close look at the course topics, and I found it interesting that most of the topics listed have a connection to statistics. I also fully understand the grading breakdown, policies, and student learning outcomes.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/LIS4317-Visual-Analytics-Blog/blob/main/_posts/2025-08-25-module-1-assignment-1/M1A1_Visualization.png?raw=true",
    "last_modified": "2025-08-25T13:15:13-04:00",
    "input_file": {}
  }
]
